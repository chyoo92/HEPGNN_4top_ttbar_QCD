{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import h5py\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as PyG\n",
    "from torch_geometric.transforms import Distance\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Data as PyGData\n",
    "from torch_geometric.data import Data\n",
    "import sys, os\n",
    "import subprocess\n",
    "import csv, yaml\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"./python\")\n",
    "from model.allModel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--model'], dest='model', nargs=None, const=None, default='GNN1layer', type=None, choices=['GNN1layer', 'GNN2layer', 'GNN3layer', 'WF1DCNN3FC1Model'], help='model name', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--config', action='store', type=str, help='Configration file with sample information')\n",
    "parser.add_argument('-o', '--output', action='store', type=str, required=True, help='Path to output directory')\n",
    "parser.add_argument('--device', action='store', type=int, default=0, help='device name')\n",
    "parser.add_argument('--epoch', action='store', type=int, default=400,help='Number of epochs')\n",
    "parser.add_argument('--batch', action='store', type=int, default=32, help='Batch size')\n",
    "parser.add_argument('--lr', action='store', type=float, default=1e-4,help='Learning rate')\n",
    "parser.add_argument('--seed', action='store', type=int, default=12345,help='random seed')\n",
    "\n",
    "parser.add_argument('--fea', action='store', type=int, default=6, help='# fea')\n",
    "parser.add_argument('--cla', action='store', type=int, default=3, help='# class')\n",
    "\n",
    "#parser.add_argument('--r', action='store', type=float, default=0, help='device name')\n",
    "#parser.add_argument('--k', action='store', type=int, default=0, help='device name')\n",
    "\n",
    "\n",
    "models = ['GNN1layer', 'GNN2layer', 'GNN3layer','WF1DCNN3FC1Model']\n",
    "parser.add_argument('--model', choices=models, default=models[0], help='model name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parser.parse_args() ## not jupyter\n",
    "import easydict\n",
    "args = easydict.EasyDict({\n",
    "    \"config\" : 'config_test_h5.yaml' ,\n",
    "    \"output\" : '20210813_test_h5',\n",
    "    \"epoch\" : 10,\n",
    "    \"seed\" : 12345,\n",
    "    \"lr\" : 1e-4,\n",
    "    \"batch\" : 32,\n",
    "    \"model\" : 'GNN1layer',\n",
    "    \"fea\" : 6,\n",
    "    \"cla\" : 1,\n",
    "    \"device\" : 3\n",
    "\n",
    "   \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(args.config).read(), Loader=yaml.FullLoader)\n",
    "config['training']['learningRate'] = float(config['training']['learningRate'])\n",
    "if args.seed: config['training']['randomSeed1'] = args.seed\n",
    "if args.epoch: config['training']['epoch'] = args.epoch\n",
    "if args.lr: config['training']['learningRate'] = args.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(os.cpu_count())\n",
    "if torch.cuda.is_available() and args.device >= 0: torch.cuda.set_device(args.device)\n",
    "if not os.path.exists('result/' + args.output): os.makedirs('result/' + args.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QCD700 /store/hep/users/yewzzang/4top_QCD_ttbar/data_graph/pt/QCD_h5/HT700*/*.h5\n",
      "QCD1000 /store/hep/users/yewzzang/4top_QCD_ttbar/data_graph/pt/QCD_h5/HT1000*/*.h5\n",
      "QCD1500 /store/hep/users/yewzzang/4top_QCD_ttbar/data_graph/pt/QCD_h5/HT1500*/*.h5\n",
      "QCD2000 /store/hep/users/yewzzang/4top_QCD_ttbar/data_graph/pt/QCD_h5/HT2000*/*.h5\n",
      "ttbar /store/hep/users/yewzzang/4top_QCD_ttbar/data_graph/pt/ttbar_h5/*.h5\n",
      "     procName                                           fileName    weight  \\\n",
      "0      QCD700  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000131   \n",
      "1      QCD700  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000131   \n",
      "2      QCD700  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000131   \n",
      "3      QCD700  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000131   \n",
      "4      QCD700  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000131   \n",
      "...       ...                                                ...       ...   \n",
      "9187    ttbar  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000001   \n",
      "9188    ttbar  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000001   \n",
      "9189    ttbar  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000001   \n",
      "9190    ttbar  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000001   \n",
      "9191    ttbar  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000001   \n",
      "\n",
      "     label fileIdx sumweight  nEvent  \n",
      "0        0       0         0     0.0  \n",
      "1        0       1         0     0.0  \n",
      "2        0       2         0     0.0  \n",
      "3        0       3         0     0.0  \n",
      "4        0       4         0     0.0  \n",
      "...    ...     ...       ...     ...  \n",
      "9187     1    9187         0     0.0  \n",
      "9188     1    9188         0     0.0  \n",
      "9189     1    9189         0     0.0  \n",
      "9190     1    9190         0     0.0  \n",
      "9191     1    9191         0     0.0  \n",
      "\n",
      "[9192 rows x 7 columns]\n",
      "\n",
      "---------\n",
      "Label=0 sumE=366479, sumW=20.2391\n",
      "Label=1 sumE=2286310, sumW=2.5684\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "##### Define dataset instance #####\n",
    "from dataset.HEPGNNDataset_h5 import *\n",
    "dset = HEPGNNDataset_h5()\n",
    "for sampleInfo in config['samples']:\n",
    "    if 'ignore' in sampleInfo and sampleInfo['ignore']: continue\n",
    "    name = sampleInfo['name']\n",
    "    dset.addSample(name, sampleInfo['path'], weight=sampleInfo['xsec']/sampleInfo['ngen'])\n",
    "    dset.setProcessLabel(name, sampleInfo['label'])\n",
    "dset.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f703f37d430>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = [int(x*len(dset)) for x in config['training']['splitFractions']]\n",
    "lengths.append(len(dset)-sum(lengths))\n",
    "torch.manual_seed(config['training']['randomSeed1'])\n",
    "trnDset, valDset, testDset = torch.utils.data.random_split(dset, lengths)\n",
    "\n",
    "\n",
    "kwargs = {'num_workers':min(config['training']['nDataLoaders'],os.cpu_count()), 'pin_memory':False}\n",
    "\n",
    "trnLoader = DataLoader(trnDset, batch_size=args.batch, shuffle=True, **kwargs)\n",
    "valLoader = DataLoader(valDset, batch_size=args.batch, shuffle=False, **kwargs)\n",
    "torch.manual_seed(torch.initial_seed())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Define model instance #####\n",
    "exec('model = '+args.model+'(fea=args.fea, cla=args.cla)')\n",
    "torch.save(model, os.path.join('result/' + args.output, 'model.pth'))\n",
    "\n",
    "device = 'cpu'\n",
    "if args.device >= 0 and torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    device = 'cuda'\n",
    "\n",
    "##### Define optimizer instance #####\n",
    "optm = optim.Adam(model.parameters(), lr=config['training']['learningRate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### Start training #####\n",
    "with open('result/' + args.output+'/summary.txt', 'w') as fout:\n",
    "    fout.write(str(args))\n",
    "    fout.write('\\n\\n')\n",
    "    fout.write(str(model))\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1/10: 100%|██████████| 49740/49740 [06:33<00:00, 126.27it/s]\n",
      "  0%|          | 0/33160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7095408040771898 trn_loss\n",
      "0.795409433924894 trn_acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2067/33160 [00:08<02:11, 235.94it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c93b82202784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mnProcessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch170_pyG/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch170_pyG/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch170_pyG/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch170_pyG/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch170_pyG/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch170_pyG/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch170_pyG/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch170_pyG/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch170_pyG/lib/python3.7/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecv_handle\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;34m'''Receive a handle over a local connection.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAF_UNIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mrecvfds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mDupFd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch170_pyG/lib/python3.7/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecvfds\u001b[0;34m(sock, size)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mbytes_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mancdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecvmsg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMSG_SPACE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mancdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "bestState, bestLoss = {}, 1e9\n",
    "train = {'loss':[], 'acc':[], 'val_loss':[], 'val_acc':[]}\n",
    "nEpoch = config['training']['epoch']\n",
    "for epoch in range(nEpoch):\n",
    "    model.train()\n",
    "    trn_loss, trn_acc = 0., 0.\n",
    "    nProcessed = 0\n",
    "    optm.zero_grad()\n",
    "    test = torch.zeros(0).to(device)\n",
    "    test_l = torch.zeros(0).to(device)\n",
    "    for i, data in enumerate(tqdm(trnLoader, desc='epoch %d/%d' % (epoch+1, nEpoch))):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        label = data.y.float().to(device=device)\n",
    "      \n",
    "            \n",
    "        scale = data.ss.float().to(device)\n",
    "        weight = data.ww.float().to(device)\n",
    "        scaledweight = weight*scale\n",
    "        scaledweight = torch.abs(scaledweight)\n",
    "        \n",
    "#         print(scale, scale.shape,'scale')\n",
    "#         print(weight, weight.shape, 'weight')\n",
    "#         print(scaledweight,scaledweight.shape, 'sc')\n",
    "     \n",
    "        test = torch.cat((test, scaledweight),0)\n",
    "        test_l = torch.cat((test_l,label),0)\n",
    "        pred = model(data)\n",
    "      \n",
    "        if args.cla ==3:\n",
    "            crit = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "            loss = crit(pred, label)\n",
    "            loss = loss * scaledweight\n",
    "            loss.mean().backward()\n",
    "\n",
    "            optm.step()\n",
    "            optm.zero_grad()\n",
    "\n",
    "\n",
    "            ibatch = len(label)\n",
    "            nProcessed += ibatch\n",
    "\n",
    "            pred = torch.argmax(pred, 1)\n",
    "            trn_loss += loss.mean().item()*ibatch\n",
    "            trn_acc += accuracy_score(label.to('cpu'), pred.to('cpu'), \n",
    "                                      sample_weight=scaledweight.to('cpu'))*ibatch\n",
    "        else:\n",
    "            crit = torch.nn.BCEWithLogitsLoss(weight=scaledweight) ### sacledweight np.abs()\n",
    "      \n",
    "            loss = crit(pred.view(-1), label)\n",
    "            loss.backward()\n",
    "\n",
    "            optm.step()\n",
    "            optm.zero_grad()\n",
    "\n",
    "            label = label.reshape(-1)\n",
    "            ibatch = len(label)\n",
    "            nProcessed += ibatch\n",
    "            trn_loss += loss.item()*ibatch\n",
    "            \n",
    "            trn_acc += accuracy_score(label.to('cpu'), np.where(pred.to('cpu') > 0.5, 1, 0), \n",
    "                                      sample_weight=scaledweight.to('cpu'))*ibatch\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    trn_loss /= nProcessed \n",
    "    trn_acc  /= nProcessed\n",
    "    print(trn_loss,'trn_loss')\n",
    "    print(trn_acc,'trn_acc')\n",
    "    model.eval()\n",
    "    val_loss, val_acc = 0., 0.\n",
    "    nProcessed = 0\n",
    "    for i, data in enumerate(tqdm(valLoader)):\n",
    "        \n",
    "        data = data.to(device)\n",
    "\n",
    "        label = data.y.float().to(device=device)\n",
    "        scale = data.ss.float().to(device)\n",
    "        weight = data.ww.float().to(device)\n",
    "        scaledweight = weight*scale\n",
    "        scaledweight = torch.abs(scaledweight)\n",
    "        test = torch.cat((test, scaledweight),0)\n",
    "        test_l = torch.cat((test_l,label),0)   \n",
    "        \n",
    "        pred = model(data)\n",
    "        if args.cla == 3:\n",
    "            crit = nn.CrossEntropyLoss(reduction='none')\n",
    "            loss = crit(pred, label)\n",
    "            loss = loss * scaledweight\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ibatch = len(label)\n",
    "            nProcessed += ibatch\n",
    "\n",
    "            pred=torch.argmax(pred,1)\n",
    "            val_loss += loss.mean().item()*ibatch\n",
    "            val_acc += accuracy_score(label.to('cpu'), pred.to('cpu'), \n",
    "                                      sample_weight=scaledweight.to('cpu'))*ibatch\n",
    "        else:\n",
    "            crit = torch.nn.BCEWithLogitsLoss(weight=scaledweight)\n",
    "            loss = crit(pred.view(-1), label)\n",
    "\n",
    "            label = label.reshape(-1)\n",
    "            ibatch = len(label)\n",
    "            nProcessed += ibatch\n",
    "            val_loss += loss.item()*ibatch\n",
    "       \n",
    "            val_acc += accuracy_score(label.to('cpu'), np.where(pred.to('cpu') > 0.5, 1, 0), \n",
    "                                      sample_weight=scaledweight.to('cpu'))*ibatch\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    val_loss /= nProcessed\n",
    "    val_acc  /= nProcessed\n",
    "    print(val_loss,'val_loss')\n",
    "    print(val_acc,'val_acc')\n",
    "    if bestLoss > val_loss:\n",
    "        bestState = model.to('cpu').state_dict()\n",
    "        bestLoss = val_loss\n",
    "        torch.save(bestState, os.path.join('result/' + args.output, 'weight.pth'))\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "    train['loss'].append(trn_loss)\n",
    "    train['acc'].append(trn_acc)\n",
    "    train['val_loss'].append(val_loss)\n",
    "    train['val_acc'].append(val_acc)\n",
    "\n",
    "    with open(os.path.join('result/' + args.output, 'train.csv'), 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        keys = train.keys()\n",
    "        writer.writerow(keys)\n",
    "        for row in zip(*[train[key] for key in keys]):\n",
    "            writer.writerow(row)\n",
    "\n",
    "bestState = model.to('cpu').state_dict()\n",
    "torch.save(bestState, os.path.join('result/' + args.output, 'weightFinal.pth'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test_l==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test_l==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test_l==0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test_l==1].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
