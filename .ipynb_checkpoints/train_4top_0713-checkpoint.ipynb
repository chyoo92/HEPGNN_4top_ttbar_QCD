{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import h5py\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as PyG\n",
    "from torch_geometric.transforms import Distance\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Data as PyGData\n",
    "from torch_geometric.data import Data\n",
    "import sys, os\n",
    "import subprocess\n",
    "import csv, yaml\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"./python\")\n",
    "from model.allModel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--model'], dest='model', nargs=None, const=None, default='GNN1layer', type=None, choices=['GNN1layer', 'GNN2layer', 'GNN3layer', 'WF1DCNN3FC1Model'], help='model name', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--config', action='store', type=str, help='Configration file with sample information')\n",
    "parser.add_argument('-o', '--output', action='store', type=str, required=True, help='Path to output directory')\n",
    "parser.add_argument('--device', action='store', type=int, default=0, help='device name')\n",
    "parser.add_argument('--epoch', action='store', type=int, default=400,help='Number of epochs')\n",
    "parser.add_argument('--batch', action='store', type=int, default=32, help='Batch size')\n",
    "parser.add_argument('--lr', action='store', type=float, default=1e-4,help='Learning rate')\n",
    "parser.add_argument('--seed', action='store', type=int, default=12345,help='random seed')\n",
    "\n",
    "parser.add_argument('--fea', action='store', type=int, default=6, help='# fea')\n",
    "parser.add_argument('--cla', action='store', type=int, default=3, help='# class')\n",
    "\n",
    "#parser.add_argument('--r', action='store', type=float, default=0, help='device name')\n",
    "#parser.add_argument('--k', action='store', type=int, default=0, help='device name')\n",
    "\n",
    "\n",
    "models = ['GNN1layer', 'GNN2layer', 'GNN3layer','WF1DCNN3FC1Model']\n",
    "parser.add_argument('--model', choices=models, default=models[0], help='model name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parser.parse_args() ## not jupyter\n",
    "import easydict\n",
    "args = easydict.EasyDict({\n",
    "    \"config\" : 'config_test.yaml' ,\n",
    "    \"output\" : '20210721_test',\n",
    "    \"epoch\" : 10,\n",
    "    \"seed\" : 12345,\n",
    "    \"lr\" : 1e-4,\n",
    "    \"batch\" : 32,\n",
    "    \"model\" : 'GNN1layer',\n",
    "    \"fea\" : 6,\n",
    "    \"cla\" : 1,\n",
    "    \"device\" : 3\n",
    "\n",
    "   \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(args.config).read(), Loader=yaml.FullLoader)\n",
    "config['training']['learningRate'] = float(config['training']['learningRate'])\n",
    "if args.seed: config['training']['randomSeed1'] = args.seed\n",
    "if args.epoch: config['training']['epoch'] = args.epoch\n",
    "if args.lr: config['training']['learningRate'] = args.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(os.cpu_count())\n",
    "if torch.cuda.is_available() and args.device >= 0: torch.cuda.set_device(args.device)\n",
    "if not os.path.exists('result/' + args.output): os.makedirs('result/' + args.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QCD700 /store/hep/users/yewzzang/4top_QCD_ttbar/data_graph/pt/QCD_weight_210709/HT700_1/*-2.pt\n",
      "QCD1000 /store/hep/users/yewzzang/4top_QCD_ttbar/data_graph/pt/QCD_weight_210709/HT1000/*-2.pt\n",
      "QCD1500 /store/hep/users/yewzzang/4top_QCD_ttbar/data_graph/pt/QCD_weight_210709/HT1500/*-2.pt\n",
      "QCD2000 /store/hep/users/yewzzang/4top_QCD_ttbar/data_graph/pt/QCD_weight_210709/HT2000/*-2.pt\n",
      "ttbar /store/hep/users/yewzzang/4top_QCD_ttbar/data_graph/pt/ttbar_weight_210719/*_64*_0.pt\n",
      "    procName                                           fileName    weight  \\\n",
      "0     QCD700  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000131   \n",
      "1    QCD1000  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000076   \n",
      "2    QCD1500  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000009   \n",
      "3    QCD2000  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000004   \n",
      "4      ttbar  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000001   \n",
      "..       ...                                                ...       ...   \n",
      "110    ttbar  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000001   \n",
      "111    ttbar  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000001   \n",
      "112    ttbar  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000001   \n",
      "113    ttbar  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000001   \n",
      "114    ttbar  /store/hep/users/yewzzang/4top_QCD_ttbar/data_...  0.000001   \n",
      "\n",
      "    label fileIdx sumweight  nEvent  \n",
      "0       0       0         0     0.0  \n",
      "1       0       1         0     0.0  \n",
      "2       0       2         0     0.0  \n",
      "3       0       3         0     0.0  \n",
      "4       1       4         0     0.0  \n",
      "..    ...     ...       ...     ...  \n",
      "110     1     110         0     0.0  \n",
      "111     1     111         0     0.0  \n",
      "112     1     112         0     0.0  \n",
      "113     1     113         0     0.0  \n",
      "114     1     114         0     0.0  \n",
      "\n",
      "[115 rows x 7 columns]\n",
      "\n",
      "---------\n",
      "Label=0 sumE=1396, sumW=0.0355467\n",
      "Label=1 sumE=41703, sumW=0.0468782\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "##### Define dataset instance #####\n",
    "from dataset.HEPGNNDataset import *\n",
    "dset = HEPGNNDataset()\n",
    "for sampleInfo in config['samples']:\n",
    "    if 'ignore' in sampleInfo and sampleInfo['ignore']: continue\n",
    "    name = sampleInfo['name']\n",
    "    dset.addSample(name, sampleInfo['path'], weight=sampleInfo['xsec']/sampleInfo['ngen'])\n",
    "    dset.setProcessLabel(name, sampleInfo['label'])\n",
    "dset.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6557c6f430>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = [int(x*len(dset)) for x in config['training']['splitFractions']]\n",
    "lengths.append(len(dset)-sum(lengths))\n",
    "torch.manual_seed(config['training']['randomSeed1'])\n",
    "trnDset, valDset, testDset = torch.utils.data.random_split(dset, lengths)\n",
    "\n",
    "\n",
    "kwargs = {'num_workers':min(config['training']['nDataLoaders'],os.cpu_count()), 'pin_memory':False}\n",
    "\n",
    "trnLoader = DataLoader(trnDset, batch_size=args.batch, shuffle=True, **kwargs)\n",
    "valLoader = DataLoader(valDset, batch_size=args.batch, shuffle=False, **kwargs)\n",
    "torch.manual_seed(torch.initial_seed())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Define model instance #####\n",
    "exec('model = '+args.model+'(fea=args.fea, cla=args.cla)')\n",
    "torch.save(model, os.path.join('result/' + args.output, 'model.pth'))\n",
    "\n",
    "device = 'cpu'\n",
    "if args.device >= 0 and torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    device = 'cuda'\n",
    "\n",
    "##### Define optimizer instance #####\n",
    "optm = optim.Adam(model.parameters(), lr=config['training']['learningRate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### Start training #####\n",
    "with open('result/' + args.output+'/summary.txt', 'w') as fout:\n",
    "    fout.write(str(args))\n",
    "    fout.write('\\n\\n')\n",
    "    fout.write(str(model))\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1/1: 100%|██████████| 809/809 [00:07<00:00, 113.56it/s]\n",
      "  0%|          | 0/539 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2020932676583866 trn_loss\n",
      "0.5252642585148658 trn_acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 539/539 [00:03<00:00, 135.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.009584402044326 val_loss\n",
      "0.5414722752091536 val_acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "bestState, bestLoss = {}, 1e9\n",
    "train = {'loss':[], 'acc':[], 'val_loss':[], 'val_acc':[]}\n",
    "nEpoch = config['training']['epoch']\n",
    "for epoch in range(nEpoch):\n",
    "    model.train()\n",
    "    trn_loss, trn_acc = 0., 0.\n",
    "    nProcessed = 0\n",
    "    optm.zero_grad()\n",
    "    test = torch.zeros(0).to(device)\n",
    "    test_l = torch.zeros(0).to(device)\n",
    "    for i, data in enumerate(tqdm(trnLoader, desc='epoch %d/%d' % (epoch+1, nEpoch))):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        label = data.y.float().to(device=device)\n",
    "      \n",
    "            \n",
    "        scale = data.ss.float().to(device)\n",
    "        weight = data.ww.float().to(device)\n",
    "        scaledweight = weight*scale\n",
    "        scaledweight = torch.abs(scaledweight)\n",
    "        \n",
    "#         print(scale, scale.shape,'scale')\n",
    "#         print(weight, weight.shape, 'weight')\n",
    "#         print(scaledweight,scaledweight.shape, 'sc')\n",
    "     \n",
    "        test = torch.cat((test, scaledweight),0)\n",
    "        test_l = torch.cat((test_l,label),0)\n",
    "        pred = model(data)\n",
    "      \n",
    "        if args.cla ==3:\n",
    "            crit = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "            loss = crit(pred, label)\n",
    "            loss = loss * scaledweight\n",
    "            loss.mean().backward()\n",
    "\n",
    "            optm.step()\n",
    "            optm.zero_grad()\n",
    "\n",
    "\n",
    "            ibatch = len(label)\n",
    "            nProcessed += ibatch\n",
    "\n",
    "            pred = torch.argmax(pred, 1)\n",
    "            trn_loss += loss.mean().item()*ibatch\n",
    "            trn_acc += accuracy_score(label.to('cpu'), pred.to('cpu'), \n",
    "                                      sample_weight=scaledweight.to('cpu'))*ibatch\n",
    "        else:\n",
    "            crit = torch.nn.BCEWithLogitsLoss(weight=scaledweight) ### sacledweight np.abs()\n",
    "      \n",
    "            loss = crit(pred.view(-1), label)\n",
    "            loss.backward()\n",
    "\n",
    "            optm.step()\n",
    "            optm.zero_grad()\n",
    "\n",
    "            label = label.reshape(-1)\n",
    "            ibatch = len(label)\n",
    "            nProcessed += ibatch\n",
    "            trn_loss += loss.item()*ibatch\n",
    "            \n",
    "            trn_acc += accuracy_score(label.to('cpu'), np.where(pred.to('cpu') > 0.5, 1, 0), \n",
    "                                      sample_weight=scaledweight.to('cpu'))*ibatch\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    trn_loss /= nProcessed \n",
    "    trn_acc  /= nProcessed\n",
    "    print(trn_loss,'trn_loss')\n",
    "    print(trn_acc,'trn_acc')\n",
    "    model.eval()\n",
    "    val_loss, val_acc = 0., 0.\n",
    "    nProcessed = 0\n",
    "    for i, data in enumerate(tqdm(valLoader)):\n",
    "        \n",
    "        data = data.to(device)\n",
    "\n",
    "        label = data.y.float().to(device=device)\n",
    "        scale = data.ss.float().to(device)\n",
    "        weight = data.ww.float().to(device)\n",
    "        scaledweight = weight*scale\n",
    "        scaledweight = torch.abs(scaledweight)\n",
    "        test = torch.cat((test, scaledweight),0)\n",
    "        test_l = torch.cat((test_l,label),0)   \n",
    "        \n",
    "        pred = model(data)\n",
    "        if args.cla == 3:\n",
    "            crit = nn.CrossEntropyLoss(reduction='none')\n",
    "            loss = crit(pred, label)\n",
    "            loss = loss * scaledweight\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ibatch = len(label)\n",
    "            nProcessed += ibatch\n",
    "\n",
    "            pred=torch.argmax(pred,1)\n",
    "            val_loss += loss.mean().item()*ibatch\n",
    "            val_acc += accuracy_score(label.to('cpu'), pred.to('cpu'), \n",
    "                                      sample_weight=scaledweight.to('cpu'))*ibatch\n",
    "        else:\n",
    "            crit = torch.nn.BCEWithLogitsLoss(weight=scaledweight)\n",
    "            loss = crit(pred.view(-1), label)\n",
    "\n",
    "            label = label.reshape(-1)\n",
    "            ibatch = len(label)\n",
    "            nProcessed += ibatch\n",
    "            val_loss += loss.item()*ibatch\n",
    "       \n",
    "            val_acc += accuracy_score(label.to('cpu'), np.where(pred.to('cpu') > 0.5, 1, 0), \n",
    "                                      sample_weight=scaledweight.to('cpu'))*ibatch\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    val_loss /= nProcessed\n",
    "    val_acc  /= nProcessed\n",
    "    print(val_loss,'val_loss')\n",
    "    print(val_acc,'val_acc')\n",
    "    if bestLoss > val_loss:\n",
    "        bestState = model.to('cpu').state_dict()\n",
    "        bestLoss = val_loss\n",
    "        torch.save(bestState, os.path.join('result/' + args.output, 'weight.pth'))\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "    train['loss'].append(trn_loss)\n",
    "    train['acc'].append(trn_acc)\n",
    "    train['val_loss'].append(val_loss)\n",
    "    train['val_acc'].append(val_acc)\n",
    "\n",
    "    with open(os.path.join('result/' + args.output, 'train.csv'), 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        keys = train.keys()\n",
    "        writer.writerow(keys)\n",
    "        for row in zip(*[train[key] for key in keys]):\n",
    "            writer.writerow(row)\n",
    "\n",
    "bestState = model.to('cpu').state_dict()\n",
    "torch.save(bestState, os.path.join('result/' + args.output, 'weightFinal.pth'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.86926031112671\n"
     ]
    }
   ],
   "source": [
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([41702])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test_l==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1396])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test_l==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([43098])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(41703., device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test_l==0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(42065.1250, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test_l==1].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
